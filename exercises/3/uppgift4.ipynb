{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "a) What is Apache Kafka, and how does it work?\n",
    "\n",
    "It´s a device that helps to streamline data between producers and consumers through events, topics, brokers, broker clusters etc. \n",
    "Apache Kafka is a distributed event streaming platform designed for high-throughput, real-time data processing. It enables applications to publish, store, process, and subscribe to streams of events in a fault-tolerant and scalable manner.\n",
    "\n",
    "✅ Kafka is mainly used for:\n",
    "\n",
    "Message Queuing (like RabbitMQ but more scalable)\n",
    "Event Streaming (for real-time data pipelines)\n",
    "Data Integration (connects databases, microservices, and cloud services)\n",
    "\n",
    "Kafka operates on a Producer-Consumer model with a log-based storage system.\n",
    "It consists of the following core components:\n",
    "\n",
    "1️⃣ Kafka Broker\n",
    "The Kafka server that stores messages and manages topics.\n",
    "A Kafka cluster consists of multiple brokers (e.g., broker-1, broker-2).\n",
    "Brokers scale horizontally, making Kafka highly fault-tolerant.\n",
    "2️⃣ Topics\n",
    "A logical category for messages (like a table in a database).\n",
    "Producers write messages to a specific topic.\n",
    "Consumers read messages from the same topic.\n",
    "Topics are divided into partitions for scalability.\n",
    "3️⃣ Partitions\n",
    "A topic is split into partitions to allow parallel processing.\n",
    "Each partition stores messages in an ordered log.\n",
    "Kafka distributes partitions across brokers for load balancing.\n",
    "Each partition has a leader and replicas for fault tolerance.\n",
    "4️⃣ Producers\n",
    "Send (produce) messages to a topic.\n",
    "Decide which partition to send data to (either randomly or via a key-based hash).\n",
    "Example: A microservice sending user activity logs to Kafka.\n",
    "5️⃣ Consumers\n",
    "Read (consume) messages from a topic.\n",
    "Belong to a consumer group to distribute workload.\n",
    "Example: A fraud detection service processing transactions.\n",
    "6️⃣ Consumer Groups\n",
    "Enable multiple consumers to share the workload.\n",
    "Each partition is consumed by only one consumer in a group.\n",
    "Multiple consumer groups can read the same data independently.\n",
    "\n",
    "B) What is a Kafka topic?\n",
    "\n",
    "A topic is a logged container where events are stored. Kafka topic is a logical channel where messages (events) are stored and categorized in Apache Kafka.\n",
    "\n",
    "\n",
    "C) What is a Kafka topic?\n",
    "\n",
    "Kafka Cluster (Multiple Brokers)\n",
    " ├── Topic: orders  (Logical category)\n",
    " │    ├── Partition 0 (Stored on Broker 1) → [Event 1 → Event 2 → Event 3]\n",
    " │    ├── Partition 1 (Stored on Broker 2) → [Event 4 → Event 5 → Event 6]\n",
    " │    ├── Partition 2 (Stored on Broker 3) → [Event 7 → Event 8 → Event 9]\n",
    " │\n",
    " ├── Topic: payments\n",
    " │    ├── Partition 0 (Stored on Broker 2) → [Event 10 → Event 11]\n",
    " │    ├── Partition 1 (Stored on Broker 3) → [Event 12 → Event 13]\n",
    "\n",
    "Kafka Cluster (Multiple Brokers)\n",
    " ├── Topic: orders  (Main folder)\n",
    " │    ├── Partition 0 (Subfolder) → [Message 1 → Message 4 → Message 7]\n",
    " │    ├── Partition 1 (Subfolder) → [Message 2 → Message 5 → Message 8]\n",
    " │    ├── Partition 2 (Subfolder) → [Message 3 → Message 6 → Message 9]\n",
    " D) What are Kafka producers and consumers and the publish-subscribe model?\n",
    "\n",
    "Producers send/push data to topics without knowing who will consume it.\n",
    "\n",
    "Consumers read/subrscribe to one or more topics in their own pace without knwoing who the producer is.\n",
    "\n",
    "Publish-Subscribe Model\n",
    "Kafka follows a publish-subscribe (pub-sub) messaging model, where:\n",
    "\n",
    "Producers publish messages to topics.\n",
    "Consumers subscribe to topics to receive messages.\n",
    "Kafka brokers store messages in a distributed, durable, and fault-tolerant way.\n",
    "Consumers can either:\n",
    "Read all messages (like a log-based system).\n",
    "Read only the latest messages (like a real-time stream).\n",
    "This model allows Kafka to handle high-throughput, real-time data streaming efficiently.\n",
    "\n",
    "E) How does Kafka guarantee message ordering?\n",
    "\n",
    "Within the partition they are appended in the order they are recieved. \n",
    "\n",
    "Producer-Side Ordering\n",
    "If a single producer sends messages to a single partition, Kafka guarantees they will be read in the same order they were sent.\n",
    "If multiple producers write to the same topic, ordering is maintained only within individual partitions, not across the entire topic.\n",
    "3. Consumer-Side Ordering\n",
    "\n",
    "  F) What is key-based partitioning in Kafka?\n",
    "\n",
    "  Key-based partitioning in Kafka is a strategy where messages with the same key are always sent to the same partition. This ensures ordering guarantees for messages with the same key.\n",
    "\n",
    "  G)  How do you setup Kafka locally?\n",
    "\n",
    "  - First install Docker.\n",
    "  - Then create a local docker-compose.yml file\n",
    "  - Then run docker compose up -d locally\n",
    "\n",
    "  Or download it manually.\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Terminology\tExplanation\n",
    "Kafka\t          A distributed event streaming platform that allows producing, storing, and consuming real-time data streams.\n",
    "Event\t           A single record/message that represents something happening, such as an order placed or a user logging in.\n",
    "Message\t               A unit of data sent to Kafka, typically consisting of a key, value, timestamp, and headers.\n",
    "Producer\t              A Kafka client (script or program) that sends messages (events) to a Kafka topic.\n",
    "Consumer\t                 A Kafka client (script or program) that reads messages from a Kafka topic.\n",
    "Topic\t                       A logical category (like a folder) where Kafka messages are stored. Topics allow producers and consumers to communicate asynchronously.\n",
    "Publish\t            The act of a producer sending a message (event) to a Kafka topic.\n",
    "Subscribe\t             The act of a consumer registering to a Kafka topic to continuously receive messages from it.\n",
    "Sink\t                  A destination where processed Kafka data is sent, such as a database, data warehouse, or another system.\n",
    "Publish-Subscribe Model\t                   A messaging pattern where producers publish messages to topics, and consumers subscribe to topics to receive them asynchronously.\n",
    "Source System\t                   The origin of data that is ingested into Kafka, such as an API, database, application logs, or IoT devices.\n",
    "Partition\t                     A subdivision of a Kafka topic that distributes messages across brokers for scalability, ordering, and parallel processing.\n",
    "Serialization\t                  The process of converting structured data (JSON, Avro, Protobuf) into a format suitable for sending to Kafka.\n",
    "Deserialization\t                 The process of converting received Kafka data into a readable format for consumers.\n",
    "Pull Model\t                     A consumer-driven model where Kafka consumers request (pull) messages from a topic at their own pace.\n",
    "Push Model\t                       A producer-driven model where the system actively sends (pushes) messages to consumers (Kafka does not use this).\n",
    "Client\t                      A producer or consumer application that interacts with Kafka to either send or receive messages.\n",
    "Advertise\t                    A Kafka broker setting that tells producers and consumers the public address of the broker for communication.\n",
    "Ports Mapping\t                     In Docker, it refers to mapping a port on the host machine to a port in the container, e.g., 9092:9092 for Kafka.\n",
    "Detached Mode\t                       Running a Docker container in the background (docker-compose up -d), allowing you to use the terminal freely.\n",
    "docker exec -it                 \tA command to interactively log into a running Docker container, useful for debugging Kafka (docker exec -it kafka bash)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
